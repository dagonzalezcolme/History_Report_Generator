{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Researcher Agent\n"
      ],
      "metadata": {
        "id": "r8XhQp-FMndd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install langgraph\n",
        "!pip install langchain_openai\n",
        "!pip install python-dotenv\n",
        "!pip install langchain_core\n",
        "!pip install IPython\n",
        "!pip install langchain-groq\n",
        "!pip install google-search-results\n",
        "!pip install langchain_community\n",
        "!pip install wikipedia\n",
        "!pip install requests"
      ],
      "metadata": {
        "id": "dIjGSYieNGwn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xKbQfFMMMapn"
      },
      "outputs": [],
      "source": [
        "from typing import Dict, TypedDict, Optional, List, Any, Annotated\n",
        "from langgraph.graph import START, StateGraph, END\n",
        "from langchain_core.prompts import ChatPromptTemplate\n",
        "from langgraph.prebuilt import ToolNode, tools_condition, create_react_agent\n",
        "from langchain_core.tools import tool,Tool\n",
        "from langgraph.checkpoint.memory import MemorySaver\n",
        "from google.colab import userdata\n",
        "from langchain_groq import ChatGroq\n",
        "from groq import Groq\n",
        "\n",
        "from langchain_community.utilities import SerpAPIWrapper,WikipediaAPIWrapper\n",
        "from langchain.agents import AgentExecutor, tool_calling_agent, create_tool_calling_agent\n",
        "from langchain_community.tools import WikipediaQueryRun\n",
        "\n",
        "from IPython.display import display, Image\n",
        "from langchain_core.runnables.graph import MermaidDrawMethod\n",
        "from dotenv import load_dotenv\n",
        "import os, re\n",
        "import requests\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Load Secrets"
      ],
      "metadata": {
        "id": "Hxxuj-IVNaq8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import userdata\n",
        "import os\n",
        "\n",
        "# Retrieve the API key from Colab's user data secrets\n",
        "GROQ_API_KEY = userdata.get('GROQ_API_KEY')\n",
        "SERP_API_KEY = userdata.get('SERP_API_KEY')\n",
        "DPLA_API_KEY = userdata.get('DPLA_API_KEY')\n",
        "\n",
        "# Check if the API key was retrieved successfully\n",
        "if not GROQ_API_KEY:\n",
        "    raise ValueError(\"GROQ_API_KEY not found in Colab secrets. Please add it.\")\n",
        "\n",
        "if not SERP_API_KEY:\n",
        "    raise ValueError(\"SERP_API_KEY not found in Colab secrets. Please add it.\")\n",
        "\n",
        "if not DPLA_API_KEY:\n",
        "    raise ValueError(\"DPLA_API_KEY not found in Colab secrets. Please add it.\")\n",
        "\n",
        "# Set the environment variables\n",
        "os.environ['GROQ_API_KEY'] = GROQ_API_KEY\n",
        "os.environ['SERP_API_KEY'] = SERP_API_KEY\n",
        "os.environ['DPLA_API_KEY'] = DPLA_API_KEY\n",
        "\n",
        "llm = \"meta-llama/llama-4-scout-17b-16e-instruct\"\n",
        "chat_groq_llm = ChatGroq(model_name=llm, groq_api_key=GROQ_API_KEY)"
      ],
      "metadata": {
        "id": "PGQQ9UTCNLvi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "research_planning_message = \"\"\"\n",
        "You are a Research Planning Agent. Your goal is to create a structured plan to get the necessary information for a given research topic provided by the user.\n",
        "\n",
        "Responsibilities:\n",
        "- Understand the user's research topic.\n",
        "- Break down the research topic into key questions or areas to investigate.\n",
        "- Structure the research process into a clear, step-by-step plan.\n",
        "- Highlight important aspects or keywords from the prompt that should be prioritized in the research.\n",
        "\n",
        "Behavior:\n",
        "- Analyze the input prompt carefully to grasp the core research need.\n",
        "- If the query mentions \"primary source documents\" or \"letters\", ensure the plan includes a step instructing the use of the `dpla_search` tool.\n",
        "- Present the plan in a clear, organized, and easy-to-follow format.\n",
        "- Be concise and focused on the planning aspect, not the research execution itself.\n",
        "\n",
        "Outputs:\n",
        "- A structured research plan, potentially including:\n",
        "    - A breakdown of the topic into sub-questions.\n",
        "    - Suggested keywords for searching\n",
        "    - Key points from the original prompt to keep in mind.\n",
        "\"\"\"\n",
        "\n",
        "researcher_agent_message = \"\"\"\n",
        "You are a highly skilled Archival Researcher Agent. Your mission is to write a COMPREHENSIVE and DETAILED report based on the provided research plan.\n",
        "\n",
        "You MUST follow this workflow exactly:\n",
        "1.  Analyze the research plan you are given. It contains multiple research questions.\n",
        "2.  Address EACH research question ONE BY ONE, in sequence.\n",
        "3.  For EACH individual question, you MUST use your search tools to gather detailed information. Find specific facts, dates, names, and context.\n",
        "4.  After researching a question, write a thorough, multi-paragraph answer for that specific question.\n",
        "5.  Once you have answered ALL of the questions in the plan, compile all your answers into a single, final report.\n",
        "6.  The final report MUST be well-structured, using a clear heading for each research question from the original plan.\n",
        "7.  DO NOT stop after answering only one question.\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "2MV9PznxOV_r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "df66d538"
      },
      "source": [
        "@tool\n",
        "def extract_info(query: str):\n",
        "    \"\"\"\n",
        "    Understands the user's input/query and breaks it down into the historical topic and time period, returning.\n",
        "\n",
        "    Parameters:\n",
        "        str: The user's historical query.\n",
        "\n",
        "    Returns:\n",
        "        str: A formatted string containing the extracted information.\n",
        "    \"\"\"\n",
        "    # Use the LLM to extract the historical topic and time period from the query\n",
        "    # Instruct the LLM to format the output as a simple string\n",
        "    prompt = f\"\"\"\n",
        "    From the following historical research query, extract the main historical topic, the specific time period, location, and group of people involved.\n",
        "    If a value is not present in the query, use the general value linked to the topic.\n",
        "\n",
        "    Query: {query}\n",
        "\n",
        "    Format the output as a single string like this:\n",
        "    Topic: [Extracted Topic] | Time Period: [Extracted Time Period] | Location: [Extracted Location] | Group of People involved: [Extracted Group of People]\n",
        "    \"\"\"\n",
        "    response = chat_groq_llm.invoke(prompt)\n",
        "    return response.content\n",
        "\n",
        "\n",
        "@tool\n",
        "def generate_plan(info_string: str):\n",
        "    \"\"\"\n",
        "    Takes a formatted string from extract_info to plan the research.\n",
        "\n",
        "    Args:\n",
        "        str: Expected format: \"Topic: [...] | Time Period: [...] | Location: [...] | Group of People involved: [...]\"\n",
        "\n",
        "    Returns:\n",
        "        str: A structured research plan based on the extracted information.\n",
        "    \"\"\"\n",
        "    # Parse the information from the formatted string\n",
        "    info = {}\n",
        "    for part in info_string.split(\" | \"):\n",
        "        if \":\" in part:\n",
        "            key, value = part.split(\":\", 1)\n",
        "            info[key.strip()] = value.strip()\n",
        "\n",
        "    # Get the extracted information, defaulting to \"N/A\" if parsing fails or key is missing\n",
        "    topic = info.get(\"Topic\", \"N/A\")\n",
        "    time_period = info.get(\"Time Period\", \"N/A\")\n",
        "    location = info.get(\"Location\", \"N/A\")\n",
        "    group_involved = info.get(\"Group of People involved\", \"N/A\")\n",
        "\n",
        "    # Use the LLM to generate a research plan based on the extracted information\n",
        "    prompt = f\"\"\"\n",
        "    Based on the following historical information:\n",
        "\n",
        "    Topic: {topic}\n",
        "    Time Period: {time_period}\n",
        "    Location: {location}\n",
        "    Group of People involved: {group_involved}\n",
        "\n",
        "    Create a plan that includes:\n",
        "    - Five specific research questions to answer based on the topic, time period, location, and group involved.\n",
        "    - Ten suggested keywords for searching the historical topic\n",
        "    -  and search strategies.\n",
        "\n",
        "    Format the output like this:\n",
        "    Research Questions:\n",
        "      questuion1\n",
        "      question2\n",
        "      question3\n",
        "      question4\n",
        "      question5\n",
        "\n",
        "    Suggested Keywords:\n",
        "      keyword1\n",
        "      keyword2\n",
        "      keyword3\n",
        "      keyword4\n",
        "      keyword5\n",
        "      keyword6\n",
        "      keyword7\n",
        "      keyword8\n",
        "      keyword9\n",
        "      keyword10\n",
        "    \"\"\"\n",
        "\n",
        "    response = chat_groq_llm.invoke(prompt)\n",
        "    return response.content\n",
        "\n",
        "# prompt template for input handling\n",
        "planning_prompt = ChatPromptTemplate.from_messages([\n",
        "    (\"system\", research_planning_message),\n",
        "    (\"human\", \"{input}\"),\n",
        "    (\"placeholder\", \"{agent_scratchpad}\"),\n",
        "])\n",
        "\n",
        "planning_tools = [extract_info, generate_plan]\n",
        "\n",
        "planning_agent_runnable = create_tool_calling_agent(\n",
        "    llm=chat_groq_llm,\n",
        "    tools=planning_tools,\n",
        "    prompt=planning_prompt\n",
        ")\n",
        "\n",
        "planning_agent_executor = AgentExecutor(agent=planning_agent_runnable, tools=planning_tools, verbose=True,return_intermediate_steps=True)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "search = SerpAPIWrapper(serpapi_api_key=SERP_API_KEY)\n",
        "google_search_tool = Tool(\n",
        "    name=\"google_search\",\n",
        "    description=\"Use this for general web searches, finding articles, and recent information.\",\n",
        "    func=search.run,\n",
        ")\n",
        "\n",
        "wikipedia_tool = WikipediaQueryRun(api_wrapper=WikipediaAPIWrapper())\n",
        "\n",
        "@tool\n",
        "def dpla_search(query: str) -> str:\n",
        "    \"\"\"\n",
        "    Searches the Digital Public Library of America (DPLA) for primary source historical documents, images, and records.\n",
        "    Use this to find original materials related to US history.\n",
        "    \"\"\"\n",
        "    api_key = DPLA_API_KEY\n",
        "    base_url = \"https://api.dp.la/v2/items\"\n",
        "    params = {'q': query, 'api_key': api_key, 'page_size': 5}\n",
        "\n",
        "    try:\n",
        "        response = requests.get(base_url, params=params)\n",
        "        response.raise_for_status()\n",
        "        data = response.json()\n",
        "\n",
        "        if not data.get('docs'):\n",
        "            return \"No primary sources found in the DPLA for that query.\"\n",
        "\n",
        "        results = []\n",
        "        for item in data['docs']:\n",
        "            title = item.get('sourceResource', {}).get('title', 'No Title')\n",
        "            provider = item.get('provider', {}).get('name', 'Unknown Provider')\n",
        "            link = item.get('isShownAt', 'No Link')\n",
        "            results.append(f\"Title: {title}\\nProvider: {provider}\\nLink: {link}\\n---\")\n",
        "\n",
        "        return \"\\n\".join(results)\n",
        "\n",
        "    except requests.exceptions.RequestException as e:\n",
        "        return f\"Error accessing DPLA API: {e}\"\n",
        "    except Exception as e:\n",
        "        return f\"An unexpected error occurred: {e}\"\n",
        "\n",
        "researcher_prompt = ChatPromptTemplate.from_messages([\n",
        "    (\"system\", researcher_agent_message),\n",
        "    (\"human\", \"{input}\"),\n",
        "    (\"placeholder\", \"{agent_scratchpad}\"),\n",
        "])\n",
        "\n",
        "researcher_tools = [google_search_tool, wikipedia_tool, dpla_search]\n",
        "\n",
        "researcher_agent_runnable = create_tool_calling_agent(\n",
        "    llm=chat_groq_llm,\n",
        "    tools=researcher_tools,\n",
        "    prompt=researcher_prompt\n",
        ")\n",
        "\n",
        "researcher_executor = AgentExecutor(agent=researcher_agent_runnable, tools=researcher_tools, verbose=True)\n"
      ],
      "metadata": {
        "id": "-L6ZnAWrzeOr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class AgentState(TypedDict):\n",
        "    query: str\n",
        "    research_plan: str\n",
        "    research_findings: str\n",
        "\n",
        "def planning_node(state: AgentState):\n",
        "    \"\"\"Invokes the planning agent to create a research plan.\"\"\"\n",
        "    print(\"--- ðŸ’¬ EXECUTING PLANNING NODE ---\")\n",
        "    response = planning_agent_executor.invoke({\"input\": state[\"query\"]})\n",
        "\n",
        "    clean_plan = response['intermediate_steps'][-1][1]\n",
        "\n",
        "    return {\"research_plan\": clean_plan}\n",
        "\n",
        "def research_node(state: AgentState):\n",
        "    \"\"\"Invokes the researcher agent to execute the research plan.\"\"\"\n",
        "    print(\"--- EXECUTING RESEARCH NODE ---\")\n",
        "    response = researcher_executor.invoke({\"input\": state[\"research_plan\"]})\n",
        "    return {\"research_findings\": response[\"output\"]}"
      ],
      "metadata": {
        "id": "XApAHfVQXRjh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Build and Run the Graph\n",
        "\n",
        "workflow = StateGraph(AgentState)\n",
        "\n",
        "workflow.add_node(\"planner\", planning_node)\n",
        "workflow.add_node(\"researcher\", research_node)\n",
        "\n",
        "workflow.set_entry_point(\"planner\")\n",
        "workflow.add_edge(\"planner\", \"researcher\")\n",
        "workflow.add_edge(\"researcher\", END)\n",
        "\n",
        "app = workflow.compile()\n",
        "\n",
        "print(\"--- Agent Workflow Graph ---\")\n",
        "display(Image(app.get_graph().draw_mermaid_png()))\n",
        "user_query = \"Research the causes and consequences of the French Revolution.\"\n",
        "test_query = \"Find primary source documents or letters related to the signing of the US Declaration of Independence.\"\n",
        "\n",
        "final_state = app.invoke({\"query\": test_query})\n",
        "\n",
        "print(\"\\n\\n--- FINAL GRAPH OUTPUT ---\")\n",
        "print(final_state['research_findings'])"
      ],
      "metadata": {
        "id": "VVVB385Y3f4_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "2i66lSp6xh4E"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
